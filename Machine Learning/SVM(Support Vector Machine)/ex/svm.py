import sys
import os
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn import svm
from sklearn.model_selection import train_test_split, GridSearchCV

# ğŸ”¹ í˜„ì¬ íŒŒì¼(svm.py)ì˜ ì ˆëŒ€ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ file/svm í´ë” ê²½ë¡œ ê³„ì‚°
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.abspath(os.path.join(BASE_DIR, "../../../file/svm"))

# ìƒ‰ìƒ ì •ì˜ (ë¹¨ê°•, íŒŒë‘)
red_RGB = (1, 0, 0)
blue_RGB = (0, 0, 1)
data_colors = [red_RGB, blue_RGB]


# --------------------------
# (1) í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì¢Œí‘œ ë°ì´í„° ì½ê¸°
# --------------------------
def read_points_file(filename):
    points = []
    with open(filename, "r") as f:
        for point in f:
            point = point.strip("\n").split()
            points.append([float(point[0]), float(point[1])])
    return points


# --------------------------
# (2) ë‘ ê°œì˜ í´ë˜ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì½ì–´ ê²°í•©
# --------------------------
def read_data(class_0_file, class_1_file):
    points_label0 = read_points_file(class_0_file)
    points_label1 = read_points_file(class_1_file)
    points = np.array(points_label0 + points_label1)
    labels = [0] * len(points_label0) + [1] * len(points_label1)
    return (points, labels)


# --------------------------
# (3) í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‹œê°í™”
# --------------------------
def plot_data(X_train, y_train, X_test, y_test):
    X = np.concatenate((X_train, X_test))
    y = np.concatenate((y_train, y_test))

    colors = get_colors(y)
    colors_train = get_colors(y_train)
    colors_test = get_colors(y_test)

    plt.figure(figsize=(12, 4), dpi=150)

    plt.subplot(131)
    plt.axis('equal')
    plt.scatter(X[:, 0], X[:, 1], c=colors, s=10, edgecolors=colors)
    plt.title("Data (100%)")

    plt.subplot(132)
    plt.axis('equal')
    plt.scatter(X_train[:, 0], X_train[:, 1], c=colors_train, s=10, edgecolors=colors_train)
    plt.title("Training Data (80%)")

    plt.subplot(133)
    plt.axis('equal')
    plt.scatter(X_test[:, 0], X_test[:, 1], c=colors_test, s=10, edgecolors=colors_test)
    plt.title("Test Data (20%)")

    plt.tight_layout()
    plt.show()


def get_colors(y):
    return [data_colors[label] for label in y]


def plot_decision_function(X_train, y_train, X_test, y_test, clf):
    plt.figure(figsize=(8, 4), dpi=150)

    plt.subplot(121)
    plt.title("Training data")
    plot_decision_function_helper(X_train, y_train, clf)

    plt.subplot(122)
    plt.title("Test data")
    plot_decision_function_helper(X_test, y_test, clf, True)
    plt.show()


def plot_decision_function_helper(X, y, clf, show_only_decision_function=False):
    colors = get_colors(y)
    plt.axis('equal')
    plt.tight_layout()
    plt.scatter(X[:, 0], X[:, 1], c=colors, s=10, edgecolors=colors)
    ax = plt.gca()
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()

    xx = np.linspace(xlim[0], xlim[1], 30)
    yy = np.linspace(ylim[0], ylim[1], 30)
    YY, XX = np.meshgrid(yy, xx)
    xy = np.vstack([XX.ravel(), YY.ravel()]).T
    Z = clf.decision_function(xy).reshape(XX.shape)

    if show_only_decision_function:
        ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=0.5, linestyles=['-'])
    else:
        ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1],
                   alpha=0.5, linestyles=['--', '-', '--'])


# =========================================================
#  1ï¸âƒ£ Linear SVM (ì„ í˜• ë¶„ë¦¬ ê°€ëŠ¥ ë°ì´í„°)
# =========================================================
x, labels = read_data(
    os.path.join(DATA_DIR, "points_class_0.txt"),
    os.path.join(DATA_DIR, "points_class_1.txt")
)
X_train, X_test, y_train, y_test = train_test_split(x, labels, test_size=0.2, random_state=0)

print("Displaying data. Close window to continue.")
plot_data(X_train, y_train, X_test, y_test)

clf = svm.SVC(kernel='linear')
clf.fit(X_train, y_train)

print("Displaying decision function. Close window to continue.")
plot_decision_function(X_train, y_train, X_test, y_test, clf)
print("Accuracy: {}%".format(clf.score(X_test, y_test) * 100))


# =========================================================
#  2ï¸âƒ£ Linear SVM (ë…¸ì´ì¦ˆ ë°ì´í„°)
# =========================================================
x, labels = read_data(
    os.path.join(DATA_DIR, "points_class_0_noise.txt"),
    os.path.join(DATA_DIR, "points_class_1_noise.txt")
)
X_train, X_test, y_train, y_test = train_test_split(x, labels, test_size=0.2, random_state=0)

print("Displaying data. Close window to continue.")
plot_data(X_train, y_train, X_test, y_test)

clf_1 = svm.SVC(kernel='linear', C=1)
clf_1.fit(X_train, y_train)
print("Display decision function (C=1)...")
plot_decision_function(X_train, y_train, X_test, y_test, clf_1)

clf_100 = svm.SVC(kernel='linear', C=100)
clf_100.fit(X_train, y_train)

print("Accuracy(C=1): {}%".format(clf_1.score(X_test, y_test) * 100))
print("Display decision function (C=100)...")
plot_decision_function(X_train, y_train, X_test, y_test, clf_100)
print("Accuracy(C=100): {}%".format(clf_100.score(X_test, y_test) * 100))


# =========================================================
#  3ï¸âƒ£ Non-linear SVM (ë¹„ì„ í˜• ë°ì´í„°)
# =========================================================
x, labels = read_data(
    os.path.join(DATA_DIR, "points_class_0_nonLinear.txt"),
    os.path.join(DATA_DIR, "points_class_1_nonLinear.txt")
)
X_train, X_test, y_train, y_test = train_test_split(x, labels, test_size=0.2, random_state=0)

print("Displaying data.")
plot_data(X_train, y_train, X_test, y_test)

print("Training SVM ...")
clf = svm.SVC(C=10.0, kernel='rbf', gamma=0.1)
clf.fit(X_train, y_train)

print("Displaying decision function.")
plot_decision_function(X_train, y_train, X_test, y_test, clf)


# =========================================================
#  4ï¸âƒ£ Grid Search (ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°)
# =========================================================
print("Performing grid search ... ")

param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001, 0.00001, 10]
}

clf_grid = GridSearchCV(svm.SVC(), param_grid, verbose=1)
clf_grid.fit(X_train, y_train)

print("Best Parameters:\n", clf_grid.best_params_)
print("Best Estimators:\n", clf_grid.best_estimator_)

print("Displaying decision function for best estimator.")
plot_decision_function(X_train, y_train, X_test, y_test, clf_grid)

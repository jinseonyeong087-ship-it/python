# ==========================
# ğŸ“˜ Support Vector Machine(SVM) ì˜ˆì œ
# ==========================

import sys
import os
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn import svm
from sklearn.model_selection import train_test_split, GridSearchCV
# from utils import read_data, plot_data, plot_decision_function   # (ì™¸ë¶€ ëª¨ë“ˆ ì—†ì´ ì§ì ‘ ì •ì˜)

# ìƒ‰ìƒ ì •ì˜ (ë¹¨ê°•, íŒŒë‘)
red_RGB = (1, 0, 0)
blue_RGB = (0, 0, 1)
data_colors = [red_RGB, blue_RGB]


# --------------------------
# (1) í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì¢Œí‘œ ë°ì´í„° ì½ê¸°
# --------------------------
def read_points_file(filename):
    points = []
    with open(filename, "r") as f:
        for point in f:
            point = point.strip("\n").split()    # ì¤„ë°”ê¿ˆ ì œê±° í›„ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
            points.append([float(point[0]), float(point[1])])   # ë¬¸ìì—´ â†’ ì‹¤ìˆ˜ ë³€í™˜
    return points


# --------------------------
# (2) ë‘ ê°œì˜ í´ë˜ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì½ì–´ ê²°í•©
# --------------------------
def read_data(class_0_file, class_1_file):
    points_label0 = read_points_file(class_0_file)   # class 0 (ì˜ˆ: íŒŒë€ ì )
    points_label1 = read_points_file(class_1_file)   # class 1 (ì˜ˆ: ë¹¨ê°„ ì )

    # ë‘ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ í•©ì¹˜ê³  numpy ë°°ì—´ë¡œ ë³€í™˜
    points = np.array(points_label0 + points_label1)

    # ë ˆì´ë¸”(label) ìƒì„±
    num_of_label0, num_of_label1 = len(points_label0), len(points_label1)
    labels = [0] * num_of_label0 + [1] * num_of_label1

    return (points, labels)


# --------------------------
# (3) í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‹œê°í™”
# --------------------------
def plot_data(X_train, y_train, X_test, y_test):
    # í•™ìŠµ+í…ŒìŠ¤íŠ¸ ë°ì´í„° í•©ì¹˜ê¸° (ì „ì²´ ë¶„í¬ í™•ì¸ìš©)
    X = np.concatenate((X_train, X_test))
    y = np.concatenate((y_train, y_test))

    colors = get_colors(y)
    colors_train = get_colors(y_train)
    colors_test = get_colors(y_test)

    plt.figure(figsize=(12, 4), dpi=150)

    # ì „ì²´ ë°ì´í„° (100%)
    plt.subplot(131)
    plt.axis('equal')
    plt.scatter(X[:, 0], X[:, 1], c=colors, s=10, edgecolors=colors)
    plt.title("Data (100%)")

    # í•™ìŠµ ë°ì´í„° (80%)
    plt.subplot(132)
    plt.axis('equal')
    plt.scatter(X_train[:, 0], X_train[:, 1], c=colors_train, s=10, edgecolors=colors_train)
    plt.title("Training Data (80%)")

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° (20%)
    plt.subplot(133)
    plt.axis('equal')
    plt.scatter(X_test[:, 0], X_test[:, 1], c=colors_test, s=10, edgecolors=colors_test)
    plt.title("Test Data (20%)")

    plt.tight_layout()
    plt.show()


# --------------------------
# (4) ë ˆì´ë¸”ë³„ ìƒ‰ìƒ ë°˜í™˜ í•¨ìˆ˜
# --------------------------
def get_colors(y):
    return [data_colors[label] for label in y]


# --------------------------
# (5) SVMì˜ ê²°ì • ê²½ê³„(Decision Boundary) ì‹œê°í™”
# --------------------------
def plot_decision_function(X_train, y_train, X_test, y_test, clf):
    plt.figure(figsize=(8, 4), dpi=150)

    plt.subplot(121)
    plt.title("Training data")
    plot_decision_function_helper(X_train, y_train, clf)

    plt.subplot(122)
    plt.title("Test data")
    plot_decision_function_helper(X_test, y_test, clf, True)

    plt.show()


# --------------------------
# (6) ì‹¤ì œ ê²°ì • ê²½ê³„ ê³„ì‚° ë° ê·¸ë¦¬ê¸°
# --------------------------
def plot_decision_function_helper(X, y, clf, show_only_decision_function=False):
    colors = get_colors(y)
    plt.axis('equal')
    plt.tight_layout()

    plt.scatter(X[:, 0], X[:, 1], c=colors, s=10, edgecolors=colors)
    ax = plt.gca()
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()

    # ê²°ì •í•¨ìˆ˜ ì‹œê°í™”ë¥¼ ìœ„í•œ ê²©ì(grid) ìƒì„±
    xx = np.linspace(xlim[0], xlim[1], 30)
    yy = np.linspace(ylim[0], ylim[1], 30)
    YY, XX = np.meshgrid(yy, xx)
    xy = np.vstack([XX.ravel(), YY.ravel()]).T

    # ê° grid pointì˜ decision value ê³„ì‚°
    Z = clf.decision_function(xy).reshape(XX.shape)

    # ê²½ê³„ì„ ë§Œ í‘œì‹œ
    if show_only_decision_function:
        ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=0.5, linestyles=['-'])
    else:
        # ê²°ì •ê²½ê³„(0) + ë§ˆì§„(-1, +1) í‘œì‹œ
        ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1],
                   alpha=0.5, linestyles=['--', '-', '--'])


# =========================================================
#  1ï¸âƒ£ Linear SVM (ì„ í˜• ë¶„ë¦¬ ê°€ëŠ¥ ë°ì´í„°)
# =========================================================

# txt íŒŒì¼ì—ì„œ ë°ì´í„° ì½ê¸°
x, labels = read_data("points_class_0.txt", "points_class_1.txt")

# 80:20 ë¹„ìœ¨ë¡œ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(x, labels, test_size=0.2, random_state=0)

print("Displaying data. Close window to continue.")
plot_data(X_train, y_train, X_test, y_test)

# SVM ë¶„ë¥˜ê¸° ìƒì„± (ì„ í˜• ì»¤ë„)
clf = svm.SVC(kernel='linear')

# í•™ìŠµ
clf.fit(X_train, y_train)

print("Displaying decision function. Close window to continue.")
plot_decision_function(X_train, y_train, X_test, y_test, clf)

# í…ŒìŠ¤íŠ¸ ì •í™•ë„ ì¶œë ¥
print("Accuracy: {}%".format(clf.score(X_test, y_test) * 100))


# =========================================================
#  2ï¸âƒ£ Linear SVM (ë…¸ì´ì¦ˆê°€ ìˆëŠ” ë°ì´í„°)
# =========================================================

x, labels = read_data("points_class_0_noise.txt", "points_class_1_noise.txt")
X_train, X_test, y_train, y_test = train_test_split(x, labels, test_size=0.2, random_state=0)

print("Displaying data. Close window to continue.")
plot_data(X_train, y_train, X_test, y_test)

# C=1 (ë§ˆì§„ í¬ê²Œ, ì˜¤ì°¨ í—ˆìš©)
clf_1 = svm.SVC(kernel='linear', C=1)
clf_1.fit(X_train, y_train)
print("Display decision function (C=1)...")
plot_decision_function(X_train, y_train, X_test, y_test, clf_1)

# C=100 (ë§ˆì§„ ì‘ê²Œ, ì˜¤ì°¨ ìµœì†Œí™”)
clf_100 = svm.SVC(kernel='linear', C=100)
clf_100.fit(X_train, y_train)

print("Accuracy(C=1): {}%".format(clf_1.score(X_test, y_test) * 100))
print("Display decision function (C=100)...")
plot_decision_function(X_train, y_train, X_test, y_test, clf_100)
print("Accuracy(C=100): {}%".format(clf_100.score(X_test, y_test) * 100))


# =========================================================
#  3ï¸âƒ£ Non-linear SVM (ë¹„ì„ í˜• ë°ì´í„°)
# =========================================================

x, labels = read_data("points_class_0_nonLinear.txt", "points_class_1_nonLinear.txt")
X_train, X_test, y_train, y_test = train_test_split(x, labels, test_size=0.2, random_state=0)

print("Displaying data.")
plot_data(X_train, y_train, X_test, y_test)

print("Training SVM ...")
# RBF ì»¤ë„ (ë¹„ì„ í˜• ê²°ì •ê²½ê³„)
clf = svm.SVC(C=10.0, kernel='rbf', gamma=0.1)
clf.fit(X_train, y_train)

# ê²°ê³¼ ì‹œê°í™”
print("Displaying decision function.")
plot_decision_function(X_train, y_train, X_test, y_test, clf)


# =========================================================
#  4ï¸âƒ£ Grid Search (ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°)
# =========================================================

print("Performing grid search ... ")

# íƒìƒ‰í•  íŒŒë¼ë¯¸í„° ëª©ë¡
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001, 0.00001, 10]
}

# GridSearchCVë¡œ ì—¬ëŸ¬ ì¡°í•© ì‹¤í—˜
clf_grid = GridSearchCV(svm.SVC(), param_grid, verbose=1)
clf_grid.fit(X_train, y_train)

# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê²°ê³¼ ì¶œë ¥
print("Best Parameters:\n", clf_grid.best_params_)
print("Best Estimators:\n", clf_grid.best_estimator_)

# ìµœì  ëª¨ë¸ì˜ ê²°ì •ê²½ê³„ ì‹œê°í™”
print("Displaying decision function for best estimator.")
plot_decision_function(X_train, y_train, X_test, y_test, clf_grid)
